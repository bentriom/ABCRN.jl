{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup models, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SpecialFunctions\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using Distributions\n",
    "using ABCRN\n",
    "\n",
    "global n = 20\n",
    "\n",
    "struct Model1 <: Model end\n",
    "struct Model2 <: Model end\n",
    "struct Model3 <: Model end\n",
    "import ABCRN: simulate\n",
    "\n",
    "function simulate(m::Model1)\n",
    "    param = rand(Exponential(1))\n",
    "    return rand(Exponential(param), n)\n",
    "end\n",
    "function simulate(m::Model2)\n",
    "    param = rand(Normal())\n",
    "    return rand(LogNormal(param,1), n)\n",
    "end\n",
    "function simulate(m::Model3)\n",
    "    param = rand(Exponential(1))\n",
    "    return rand(Gamma(2,1/param), n)\n",
    "end\n",
    "\n",
    "m1, m2, m3 = Model1(), Model2(), Model3()\n",
    "lh_m1(s::Vector) = exp(log(gamma(n+1)) - (n+1)*log(1+s[1]))\n",
    "lh_m2(s::Vector) = exp(-s[2]^2/(2n*(n+1)) - (s[3]^2)/2 + (s[2]^2)/(2n) - s[2]) * (2pi)^(-n/2)*(n+1)^(-1/2)\n",
    "lh_m3(s::Vector) = exp(s[2])*gamma(2n+1)/gamma(2)^n * (1+s[1])^(-2n-1)\n",
    "\n",
    "ss_func(y) = [sum(y), sum(log.(y)), sum(log.(y).^2)]\n",
    "dist_l2(s_sim,s_obs) = sqrt(dot(s_sim,s_obs))\n",
    "\n",
    "observations = simulate(m3)\n",
    "ss_observations = ss_func(observations)\n",
    "models = [m1, m2, m3]\n",
    "abc_trainset = abc_model_choice_dataset(models, ss_observations, ss_func, dist_l2, 29000, 29000)\n",
    "abc_testset = abc_model_choice_dataset(models, ss_observations, ss_func, dist_l2, 1000, 1000)\n",
    "\n",
    "list_lh = [lh_m1, lh_m2, lh_m3]\n",
    "prob_model(ss::Vector, list_lh, idx_model) = list_lh[idx_model](ss) / sum([list_lh[i](ss) for i = eachindex(list_lh)])\n",
    "prob_model(ss::Vector, idx_model) = prob_model(ss, list_lh, idx_model)\n",
    "prob_model3(ss::Vector) = prob_model(ss, list_lh, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "p = plot(title=\"Trainset\")\n",
    "colors = [\"black\", \"red\", \"green\"]\n",
    "begin_idx = 1\n",
    "for i = 1:3\n",
    "    models_i = findall(x->x==i, abc_testset.models_indexes)\n",
    "    nbr_obs = length(models_i)\n",
    "    end_idx = begin_idx + nbr_obs - 1\n",
    "    lh = list_lh[i]\n",
    "    scatter!(p, begin_idx:end_idx, \n",
    "             vec(mapslices(prob_model3, abc_testset.summary_stats_matrix[:,models_i], dims = 1)), \n",
    "             color = colors[i], markersize = 3.0, markershape = :cross, label = \"Model $i\")\n",
    "    global begin_idx = end_idx + 1\n",
    "end\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ScikitLearn\n",
    "@sk_import linear_model: LogisticRegression\n",
    "@sk_import ensemble: RandomForestClassifier\n",
    "@sk_import metrics: (classification_report, confusion_matrix)\n",
    "@sk_import neighbors: KNeighborsClassifier\n",
    "\n",
    "X_trainset = transpose(abc_trainset.X)\n",
    "X_testset = transpose(abc_testset.X)\n",
    "\n",
    "logit_reg = fit!(LogisticRegression(), X_trainset, abc_trainset.y)\n",
    "y_pred_logit = predict(logit_reg, X_testset)\n",
    "println(classification_report(y_pred = y_pred_logit, y_true = abc_testset.y))\n",
    "\n",
    "rf_clf = fit!(RandomForestClassifier(n_estimators=500), X_trainset, abc_trainset.y)\n",
    "y_pred_rf = predict(rf_clf, X_testset)\n",
    "println(classification_report(y_pred = y_pred_rf, y_true = abc_testset.y))\n",
    "\n",
    "knn_clf = fit!(KNeighborsClassifier(n_neighbors=20), X_trainset, abc_trainset.y)\n",
    "y_pred_knn = predict(rf_clf, X_testset)\n",
    "println(classification_report(y_pred = y_pred_rf, y_true = abc_testset.y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rf = rf_abc_model_choice(models, ss_observations, ss_func, 29000; \n",
    "                             hyperparameters_range = Dict(:n_estimators => [500]))\n",
    "println(classification_report(y_pred = predict(res_rf.clf, X_testset), y_true = abc_testset.y))\n",
    "println(confusion_matrix(y_pred = predict(res_rf.clf, X_testset), y_true = abc_testset.y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_params = Dict()\n",
    "for param in keys(get_params(res_rf.clf))\n",
    "    dict_params[Symbol(param)] = get_params(res_rf.clf)[param]\n",
    "end\n",
    "RandomForestClassifier(;dict_params...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_votes = res_rf.clf.oob_decision_function_\n",
    "y_pred_oob = argmax.([oob_votes[i,:] for i = 1:size(oob_votes)[1]])\n",
    "@show mean(y_pred_oob .== res_rf.reference_table.y)\n",
    "@show res_rf.clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
